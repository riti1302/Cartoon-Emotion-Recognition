{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion-Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riti1302/Cartoon-Emotion-Recognition/blob/master/Emotion_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCxPVbzxMdXT",
        "colab_type": "code",
        "outputId": "7e1b32cb-8f15-4211-d54b-61b12b79812a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPlwQVTPNHaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Emotion_recognition.zip\" -d \"./\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb-EjhOwOEws",
        "colab_type": "code",
        "outputId": "9890fcf5-7d90-4458-9699-c4d984162a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd 'Emotion_recognition'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Emotion_recognition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X232_tThPHiq",
        "colab_type": "code",
        "outputId": "e0ca321c-2ca1-411d-d917-074be89984e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "!pip3 install tensorflow==1.15.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 39kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.28.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 46.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.34.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 44.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=7d7ac417c73d9e8f1f1549c4a7d6a10920faa5aba0e4ce278fd0a452300d5712\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorboard, gast, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorflow 2.2.0rc2\n",
            "    Uninstalling tensorflow-2.2.0rc2:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc2\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deMLGJebOOLD",
        "colab_type": "code",
        "outputId": "4c4259f2-0a70-46c5-d4e8-2bdf0de10120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!sh train.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From retrain.py:1106: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:805: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "W0415 06:55:19.875270 139999072065408 module_wrapper.py:139] From retrain.py:805: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:807: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0415 06:55:19.875519 139999072065408 module_wrapper.py:139] From retrain.py:807: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            ">> Downloading inception-2015-12-05.tgz 100.0%\n",
            "Successfully downloaded inception-2015-12-05.tgz 88931400 bytes.\n",
            "WARNING:tensorflow:From retrain.py:262: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n",
            "W0415 06:55:21.923820 139999072065408 deprecation.py:323] From retrain.py:262: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n",
            "WARNING:tensorflow:From retrain.py:263: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "W0415 06:55:21.924152 139999072065408 module_wrapper.py:139] From retrain.py:263: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "2020-04-15 06:55:22.260277: W tensorflow/core/framework/op_def_util.cc:357] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\n",
            "Looking for images in 'sad'\n",
            "Looking for images in 'angry'\n",
            "Looking for images in 'happy'\n",
            "Looking for images in 'Unknown'\n",
            "WARNING: Folder has less than 20 images, which may cause issues.\n",
            "Looking for images in 'surprised'\n",
            "WARNING:tensorflow:From retrain.py:831: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0415 06:55:22.441224 139999072065408 module_wrapper.py:139] From retrain.py:831: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-04-15 06:55:22.442599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-04-15 06:55:22.494665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-15 06:55:22.495583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-15 06:55:22.520885: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-04-15 06:55:22.760109: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-04-15 06:55:22.870452: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-04-15 06:55:22.896784: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-04-15 06:55:23.158333: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-04-15 06:55:23.295950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-04-15 06:55:23.300416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-15 06:55:23.300585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-15 06:55:23.301651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-15 06:55:23.302476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-04-15 06:55:23.302895: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-04-15 06:55:23.307721: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-04-15 06:55:23.308066: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x283abc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-15 06:55:23.308107: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-04-15 06:55:23.417116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-15 06:55:23.418212: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x283ad80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-15 06:55:23.418243: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-04-15 06:55:23.419790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-15 06:55:23.420685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-15 06:55:23.420755: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-04-15 06:55:23.420778: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-04-15 06:55:23.420796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-04-15 06:55:23.420818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-04-15 06:55:23.420855: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-04-15 06:55:23.420874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-04-15 06:55:23.420894: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-15 06:55:23.421019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-15 06:55:23.422028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-15 06:55:23.422841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-04-15 06:55:23.422887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-04-15 06:55:23.424556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-15 06:55:23.424595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-04-15 06:55:23.424611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-04-15 06:55:23.424765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-15 06:55:23.425757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-15 06:55:23.426500: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-04-15 06:55:23.426605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame253.jpg.txt\n",
            "2020-04-15 06:55:24.761725: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-15 06:55:29.772831: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame49.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame130.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame129.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame126.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame201.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame245.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame203.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame204.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame18.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame252.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame174.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame125.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame274.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame127.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame32.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame244.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame30.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame200.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame19.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame251.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame88.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame202.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame140.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame63.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame72.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame139.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame31.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame122.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame33.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame94.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame123.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame48.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame246.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame124.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame206.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame64.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame207.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame47.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame233.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame153.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame231.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame227.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame148.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame237.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame131.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame9.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame256.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame242.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame147.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame80.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame261.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame132.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame238.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame20.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame150.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame27.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame259.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame46.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame154.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame228.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame149.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame10.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame29.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame81.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame15.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame232.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame4.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame142.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame146.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame236.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame243.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame239.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame144.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame255.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame151.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame100.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame0.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame99.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame14.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame181.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame78.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame189.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame192.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame212.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame70.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame184.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame65.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame69.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame66.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame62.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame157.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame208.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame193.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame52.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame156.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame41.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame210.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame101.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame42.jpg.txt\n",
            "100 bottleneck files created.\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame266.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame182.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame84.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame209.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame191.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame183.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame1.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame34.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame211.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame17.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame56.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/Unknown/frame143.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/Unknown/frame138.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/Unknown/frame230.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/Unknown/frame229.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/Unknown/frame141.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/Unknown/frame96.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/Unknown/frame145.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame16.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame277.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame6.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame60.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame254.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame160.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame89.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame178.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame161.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame26.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame179.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame162.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame28.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame271.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame87.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame45.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame36.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame35.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame169.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame85.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame57.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame93.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame13.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame241.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame23.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame2.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame61.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame167.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame90.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame278.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame171.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame168.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame83.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame270.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame173.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame172.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame59.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame12.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame68.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame44.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame8.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame71.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame180.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame43.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame135.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame91.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame240.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame234.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame7.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame163.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame134.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame94.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame165.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame166.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame164.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame58.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame3.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame50.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame133.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame53.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame51.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame67.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame37.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame170.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame5.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame235.jpg.txt\n",
            "WARNING:tensorflow:From retrain.py:737: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0415 06:55:38.548075 139999072065408 module_wrapper.py:139] From retrain.py:737: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:741: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0415 06:55:38.549542 139999072065408 module_wrapper.py:139] From retrain.py:741: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:750: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "W0415 06:55:38.550510 139999072065408 module_wrapper.py:139] From retrain.py:750: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:707: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0415 06:55:38.568173 139999072065408 module_wrapper.py:139] From retrain.py:707: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:713: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "W0415 06:55:38.581752 139999072065408 module_wrapper.py:139] From retrain.py:713: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:768: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0415 06:55:38.606792 139999072065408 deprecation.py:323] From retrain.py:768: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:774: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "W0415 06:55:38.628795 139999072065408 module_wrapper.py:139] From retrain.py:774: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:857: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "W0415 06:55:38.674425 139999072065408 module_wrapper.py:139] From retrain.py:857: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:858: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "W0415 06:55:38.675578 139999072065408 module_wrapper.py:139] From retrain.py:858: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:865: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "W0415 06:55:39.418349 139999072065408 module_wrapper.py:139] From retrain.py:865: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "2020-04-15 06:55:40.870040: Step 0: Train accuracy = 26.0%\n",
            "2020-04-15 06:55:40.870132: Step 0: Cross entropy = 1.556131\n",
            "2020-04-15 06:55:41.608796: Step 0: Validation accuracy = 27.0% (N=100)\n",
            "2020-04-15 06:55:42.281949: Step 10: Train accuracy = 71.0%\n",
            "2020-04-15 06:55:42.282070: Step 10: Cross entropy = 1.310120\n",
            "2020-04-15 06:55:42.348960: Step 10: Validation accuracy = 54.0% (N=100)\n",
            "2020-04-15 06:55:43.017447: Step 20: Train accuracy = 75.0%\n",
            "2020-04-15 06:55:43.017530: Step 20: Cross entropy = 1.145645\n",
            "2020-04-15 06:55:43.082421: Step 20: Validation accuracy = 81.0% (N=100)\n",
            "2020-04-15 06:55:43.746742: Step 30: Train accuracy = 76.0%\n",
            "2020-04-15 06:55:43.746830: Step 30: Cross entropy = 0.941239\n",
            "2020-04-15 06:55:43.812578: Step 30: Validation accuracy = 73.0% (N=100)\n",
            "2020-04-15 06:55:44.476924: Step 40: Train accuracy = 81.0%\n",
            "2020-04-15 06:55:44.477038: Step 40: Cross entropy = 0.903699\n",
            "2020-04-15 06:55:44.540001: Step 40: Validation accuracy = 67.0% (N=100)\n",
            "2020-04-15 06:55:45.204325: Step 50: Train accuracy = 84.0%\n",
            "2020-04-15 06:55:45.204399: Step 50: Cross entropy = 0.813072\n",
            "2020-04-15 06:55:45.269208: Step 50: Validation accuracy = 80.0% (N=100)\n",
            "2020-04-15 06:55:45.939530: Step 60: Train accuracy = 78.0%\n",
            "2020-04-15 06:55:45.939620: Step 60: Cross entropy = 0.834105\n",
            "2020-04-15 06:55:46.010192: Step 60: Validation accuracy = 83.0% (N=100)\n",
            "2020-04-15 06:55:46.686219: Step 70: Train accuracy = 78.0%\n",
            "2020-04-15 06:55:46.686294: Step 70: Cross entropy = 0.782897\n",
            "2020-04-15 06:55:46.756065: Step 70: Validation accuracy = 74.0% (N=100)\n",
            "2020-04-15 06:55:47.425714: Step 80: Train accuracy = 81.0%\n",
            "2020-04-15 06:55:47.425797: Step 80: Cross entropy = 0.728158\n",
            "2020-04-15 06:55:47.490163: Step 80: Validation accuracy = 81.0% (N=100)\n",
            "2020-04-15 06:55:48.161192: Step 90: Train accuracy = 85.0%\n",
            "2020-04-15 06:55:48.161270: Step 90: Cross entropy = 0.672086\n",
            "2020-04-15 06:55:48.226579: Step 90: Validation accuracy = 80.0% (N=100)\n",
            "2020-04-15 06:55:48.882564: Step 100: Train accuracy = 92.0%\n",
            "2020-04-15 06:55:48.882637: Step 100: Cross entropy = 0.573852\n",
            "2020-04-15 06:55:48.944393: Step 100: Validation accuracy = 80.0% (N=100)\n",
            "2020-04-15 06:55:49.608057: Step 110: Train accuracy = 86.0%\n",
            "2020-04-15 06:55:49.608141: Step 110: Cross entropy = 0.612825\n",
            "2020-04-15 06:55:49.671624: Step 110: Validation accuracy = 78.0% (N=100)\n",
            "2020-04-15 06:55:50.360393: Step 120: Train accuracy = 92.0%\n",
            "2020-04-15 06:55:50.360479: Step 120: Cross entropy = 0.536408\n",
            "2020-04-15 06:55:50.426349: Step 120: Validation accuracy = 76.0% (N=100)\n",
            "2020-04-15 06:55:51.097886: Step 130: Train accuracy = 89.0%\n",
            "2020-04-15 06:55:51.098002: Step 130: Cross entropy = 0.590495\n",
            "2020-04-15 06:55:51.166387: Step 130: Validation accuracy = 75.0% (N=100)\n",
            "2020-04-15 06:55:51.839326: Step 140: Train accuracy = 89.0%\n",
            "2020-04-15 06:55:51.839399: Step 140: Cross entropy = 0.559205\n",
            "2020-04-15 06:55:51.905135: Step 140: Validation accuracy = 85.0% (N=100)\n",
            "2020-04-15 06:55:52.570760: Step 150: Train accuracy = 93.0%\n",
            "2020-04-15 06:55:52.570848: Step 150: Cross entropy = 0.495591\n",
            "2020-04-15 06:55:52.635090: Step 150: Validation accuracy = 79.0% (N=100)\n",
            "2020-04-15 06:55:53.294089: Step 160: Train accuracy = 95.0%\n",
            "2020-04-15 06:55:53.294207: Step 160: Cross entropy = 0.516430\n",
            "2020-04-15 06:55:53.361955: Step 160: Validation accuracy = 90.0% (N=100)\n",
            "2020-04-15 06:55:54.085590: Step 170: Train accuracy = 93.0%\n",
            "2020-04-15 06:55:54.085673: Step 170: Cross entropy = 0.491999\n",
            "2020-04-15 06:55:54.153711: Step 170: Validation accuracy = 81.0% (N=100)\n",
            "2020-04-15 06:55:54.821450: Step 180: Train accuracy = 96.0%\n",
            "2020-04-15 06:55:54.821556: Step 180: Cross entropy = 0.474432\n",
            "2020-04-15 06:55:54.886832: Step 180: Validation accuracy = 80.0% (N=100)\n",
            "2020-04-15 06:55:55.553371: Step 190: Train accuracy = 93.0%\n",
            "2020-04-15 06:55:55.553445: Step 190: Cross entropy = 0.445112\n",
            "2020-04-15 06:55:55.616385: Step 190: Validation accuracy = 68.0% (N=100)\n",
            "2020-04-15 06:55:56.288000: Step 200: Train accuracy = 97.0%\n",
            "2020-04-15 06:55:56.288081: Step 200: Cross entropy = 0.459678\n",
            "2020-04-15 06:55:56.351017: Step 200: Validation accuracy = 90.0% (N=100)\n",
            "2020-04-15 06:55:57.014770: Step 210: Train accuracy = 96.0%\n",
            "2020-04-15 06:55:57.014865: Step 210: Cross entropy = 0.400006\n",
            "2020-04-15 06:55:57.078931: Step 210: Validation accuracy = 77.0% (N=100)\n",
            "2020-04-15 06:55:57.750489: Step 220: Train accuracy = 95.0%\n",
            "2020-04-15 06:55:57.750570: Step 220: Cross entropy = 0.399987\n",
            "2020-04-15 06:55:57.814493: Step 220: Validation accuracy = 84.0% (N=100)\n",
            "2020-04-15 06:55:58.473215: Step 230: Train accuracy = 98.0%\n",
            "2020-04-15 06:55:58.473285: Step 230: Cross entropy = 0.370849\n",
            "2020-04-15 06:55:58.535828: Step 230: Validation accuracy = 80.0% (N=100)\n",
            "2020-04-15 06:55:59.199640: Step 240: Train accuracy = 97.0%\n",
            "2020-04-15 06:55:59.199725: Step 240: Cross entropy = 0.367684\n",
            "2020-04-15 06:55:59.264315: Step 240: Validation accuracy = 79.0% (N=100)\n",
            "2020-04-15 06:55:59.924769: Step 250: Train accuracy = 98.0%\n",
            "2020-04-15 06:55:59.924871: Step 250: Cross entropy = 0.371842\n",
            "2020-04-15 06:55:59.990715: Step 250: Validation accuracy = 76.0% (N=100)\n",
            "2020-04-15 06:56:00.645480: Step 260: Train accuracy = 97.0%\n",
            "2020-04-15 06:56:00.645616: Step 260: Cross entropy = 0.359272\n",
            "2020-04-15 06:56:00.708062: Step 260: Validation accuracy = 86.0% (N=100)\n",
            "2020-04-15 06:56:01.366347: Step 270: Train accuracy = 100.0%\n",
            "2020-04-15 06:56:01.366448: Step 270: Cross entropy = 0.350360\n",
            "2020-04-15 06:56:01.428968: Step 270: Validation accuracy = 77.0% (N=100)\n",
            "2020-04-15 06:56:02.086167: Step 280: Train accuracy = 94.0%\n",
            "2020-04-15 06:56:02.086258: Step 280: Cross entropy = 0.397118\n",
            "2020-04-15 06:56:02.150378: Step 280: Validation accuracy = 81.0% (N=100)\n",
            "2020-04-15 06:56:02.818089: Step 290: Train accuracy = 98.0%\n",
            "2020-04-15 06:56:02.818181: Step 290: Cross entropy = 0.348624\n",
            "2020-04-15 06:56:02.881950: Step 290: Validation accuracy = 83.0% (N=100)\n",
            "2020-04-15 06:56:03.540643: Step 300: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:03.540716: Step 300: Cross entropy = 0.379627\n",
            "2020-04-15 06:56:03.604222: Step 300: Validation accuracy = 76.0% (N=100)\n",
            "2020-04-15 06:56:04.260972: Step 310: Train accuracy = 97.0%\n",
            "2020-04-15 06:56:04.261072: Step 310: Cross entropy = 0.353126\n",
            "2020-04-15 06:56:04.323858: Step 310: Validation accuracy = 91.0% (N=100)\n",
            "2020-04-15 06:56:04.994876: Step 320: Train accuracy = 98.0%\n",
            "2020-04-15 06:56:04.994999: Step 320: Cross entropy = 0.321202\n",
            "2020-04-15 06:56:05.059729: Step 320: Validation accuracy = 79.0% (N=100)\n",
            "2020-04-15 06:56:05.727714: Step 330: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:05.727798: Step 330: Cross entropy = 0.254424\n",
            "2020-04-15 06:56:05.791292: Step 330: Validation accuracy = 77.0% (N=100)\n",
            "2020-04-15 06:56:06.457593: Step 340: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:06.457673: Step 340: Cross entropy = 0.343786\n",
            "2020-04-15 06:56:06.521238: Step 340: Validation accuracy = 83.0% (N=100)\n",
            "2020-04-15 06:56:07.194781: Step 350: Train accuracy = 96.0%\n",
            "2020-04-15 06:56:07.194856: Step 350: Cross entropy = 0.294712\n",
            "2020-04-15 06:56:07.257400: Step 350: Validation accuracy = 78.0% (N=100)\n",
            "2020-04-15 06:56:07.945447: Step 360: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:07.945534: Step 360: Cross entropy = 0.369786\n",
            "2020-04-15 06:56:08.009547: Step 360: Validation accuracy = 86.0% (N=100)\n",
            "2020-04-15 06:56:08.664563: Step 370: Train accuracy = 98.0%\n",
            "2020-04-15 06:56:08.664638: Step 370: Cross entropy = 0.269893\n",
            "2020-04-15 06:56:08.727862: Step 370: Validation accuracy = 78.0% (N=100)\n",
            "2020-04-15 06:56:09.381595: Step 380: Train accuracy = 98.0%\n",
            "2020-04-15 06:56:09.381670: Step 380: Cross entropy = 0.301910\n",
            "2020-04-15 06:56:09.446410: Step 380: Validation accuracy = 79.0% (N=100)\n",
            "2020-04-15 06:56:10.103786: Step 390: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:10.103878: Step 390: Cross entropy = 0.285069\n",
            "2020-04-15 06:56:10.169066: Step 390: Validation accuracy = 85.0% (N=100)\n",
            "2020-04-15 06:56:10.825376: Step 400: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:10.825486: Step 400: Cross entropy = 0.245422\n",
            "2020-04-15 06:56:10.889537: Step 400: Validation accuracy = 79.0% (N=100)\n",
            "2020-04-15 06:56:11.549722: Step 410: Train accuracy = 98.0%\n",
            "2020-04-15 06:56:11.549792: Step 410: Cross entropy = 0.268487\n",
            "2020-04-15 06:56:11.614284: Step 410: Validation accuracy = 79.0% (N=100)\n",
            "2020-04-15 06:56:12.293645: Step 420: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:12.293759: Step 420: Cross entropy = 0.233880\n",
            "2020-04-15 06:56:12.360075: Step 420: Validation accuracy = 74.0% (N=100)\n",
            "2020-04-15 06:56:13.027921: Step 430: Train accuracy = 100.0%\n",
            "2020-04-15 06:56:13.028022: Step 430: Cross entropy = 0.254580\n",
            "2020-04-15 06:56:13.093468: Step 430: Validation accuracy = 78.0% (N=100)\n",
            "2020-04-15 06:56:13.756765: Step 440: Train accuracy = 100.0%\n",
            "2020-04-15 06:56:13.756849: Step 440: Cross entropy = 0.237364\n",
            "2020-04-15 06:56:13.821658: Step 440: Validation accuracy = 71.0% (N=100)\n",
            "2020-04-15 06:56:14.491207: Step 450: Train accuracy = 100.0%\n",
            "2020-04-15 06:56:14.491290: Step 450: Cross entropy = 0.229077\n",
            "2020-04-15 06:56:14.554491: Step 450: Validation accuracy = 79.0% (N=100)\n",
            "2020-04-15 06:56:15.217391: Step 460: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:15.217482: Step 460: Cross entropy = 0.283302\n",
            "2020-04-15 06:56:15.281079: Step 460: Validation accuracy = 77.0% (N=100)\n",
            "2020-04-15 06:56:15.940674: Step 470: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:15.940769: Step 470: Cross entropy = 0.255519\n",
            "2020-04-15 06:56:16.005969: Step 470: Validation accuracy = 76.0% (N=100)\n",
            "2020-04-15 06:56:16.705565: Step 480: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:16.705662: Step 480: Cross entropy = 0.248983\n",
            "2020-04-15 06:56:16.774716: Step 480: Validation accuracy = 82.0% (N=100)\n",
            "2020-04-15 06:56:17.442260: Step 490: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:17.442354: Step 490: Cross entropy = 0.224372\n",
            "2020-04-15 06:56:17.508803: Step 490: Validation accuracy = 81.0% (N=100)\n",
            "2020-04-15 06:56:18.102961: Step 499: Train accuracy = 100.0%\n",
            "2020-04-15 06:56:18.103051: Step 499: Cross entropy = 0.222370\n",
            "2020-04-15 06:56:18.167532: Step 499: Validation accuracy = 78.0% (N=100)\n",
            "Final test accuracy = 66.7% (N=15)\n",
            "WARNING:tensorflow:From retrain.py:944: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0415 06:56:18.893560 139999072065408 deprecation.py:323] From retrain.py:944: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0415 06:56:18.893815 139999072065408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 2 variables.\n",
            "I0415 06:56:18.948931 139999072065408 graph_util_impl.py:334] Froze 2 variables.\n",
            "INFO:tensorflow:Converted 2 variables to const ops.\n",
            "I0415 06:56:18.963369 139999072065408 graph_util_impl.py:394] Converted 2 variables to const ops.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtGZVCeMQY43",
        "colab_type": "code",
        "outputId": "a8b3b1f5-a968-49be-f0a1-7ccfefdb7afa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd '../'\n",
        "!zip -r Emotion_recognition.zip Emotion_recognition"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "  adding: Emotion_recognition/ (stored 0%)\n",
            "  adding: Emotion_recognition/get_dataset.py (deflated 47%)\n",
            "  adding: Emotion_recognition/train.sh (deflated 49%)\n",
            "  adding: Emotion_recognition/tf_files/ (stored 0%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/ (stored 0%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/ (stored 0%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame139.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame18.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame48.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame125.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame127.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame251.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame174.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame33.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame253.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame88.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame274.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame49.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame64.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame32.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame245.jpg.txt (deflated 56%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame140.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame123.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame246.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame203.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame94.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame201.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame122.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame63.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame207.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame47.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame31.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame19.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame204.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame72.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame130.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame202.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame252.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame124.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame200.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame244.jpg.txt (deflated 56%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame129.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame30.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame206.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/sad/frame126.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/ (stored 0%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame131.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame81.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame256.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame239.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame228.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame27.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame147.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame227.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame144.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame142.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame146.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame243.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame151.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame10.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame149.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame46.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame132.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame148.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame259.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame154.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame9.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame238.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame242.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame29.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame150.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame232.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame80.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame233.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame261.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame15.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame4.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame153.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame237.jpg.txt (deflated 56%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame236.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame20.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame255.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/angry/frame231.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/ (stored 0%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame100.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame181.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame17.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame191.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame0.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame65.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame99.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame70.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame78.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame1.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame42.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame208.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame34.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame41.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame183.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame192.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame156.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame66.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame209.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame52.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame101.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame184.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame266.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame14.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame210.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame189.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame84.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame56.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame69.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame211.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame157.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame212.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame62.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame193.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/happy/frame182.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/Unknown/ (stored 0%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/Unknown/frame230.jpg.txt (deflated 56%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/Unknown/frame96.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/Unknown/frame141.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/Unknown/frame145.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/Unknown/frame229.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/Unknown/frame143.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/Unknown/frame138.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/ (stored 0%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame68.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame179.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame37.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame87.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame161.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame58.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame162.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame26.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame28.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame270.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame60.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame3.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame71.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame45.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame170.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame178.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame44.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame164.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame172.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame43.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame180.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame51.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame16.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame160.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame277.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame93.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame59.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame134.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame91.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame57.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame8.jpg.txt (deflated 56%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame235.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame254.jpg.txt (deflated 56%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame2.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame173.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame83.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame94.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame36.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame6.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame89.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame167.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame35.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame90.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame271.jpg.txt (deflated 56%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame5.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame166.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame23.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame171.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame85.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame12.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame241.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame169.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame50.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame168.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame133.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame240.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame61.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame67.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame165.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame278.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame7.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame13.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame135.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame53.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame163.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/bottlenecks/surprised/frame234.jpg.txt (deflated 55%)\n",
            "  adding: Emotion_recognition/tf_files/retrained_graph.pb (deflated 7%)\n",
            "  adding: Emotion_recognition/tf_files/retrained_labels.txt (stored 0%)\n",
            "  adding: Emotion_recognition/tf_files/training_summaries/ (stored 0%)\n",
            "  adding: Emotion_recognition/tf_files/training_summaries/basic/ (stored 0%)\n",
            "  adding: Emotion_recognition/tf_files/training_summaries/basic/train/ (stored 0%)\n",
            "  adding: Emotion_recognition/tf_files/training_summaries/basic/train/events.out.tfevents.1586933739.7950686b3fa1 (deflated 9%)\n",
            "  adding: Emotion_recognition/tf_files/training_summaries/basic/validation/ (stored 0%)\n",
            "  adding: Emotion_recognition/tf_files/training_summaries/basic/validation/events.out.tfevents.1586933741.7950686b3fa1 (deflated 87%)\n",
            "  adding: Emotion_recognition/classify.py (deflated 48%)\n",
            "  adding: Emotion_recognition/inception/ (stored 0%)\n",
            "  adding: Emotion_recognition/inception/LICENSE (deflated 65%)\n",
            "  adding: Emotion_recognition/inception/imagenet_2012_challenge_label_map_proto.pbtxt (deflated 88%)\n",
            "  adding: Emotion_recognition/inception/imagenet_synset_to_human_label_map.txt (deflated 60%)\n",
            "  adding: Emotion_recognition/inception/inception-2015-12-05.tgz (deflated 0%)\n",
            "  adding: Emotion_recognition/inception/cropped_panda.jpg (deflated 1%)\n",
            "  adding: Emotion_recognition/inception/classify_image_graph_def.pb (deflated 7%)\n",
            "  adding: Emotion_recognition/training_dataset/ (stored 0%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/ (stored 0%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame253.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame48.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame124.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame206.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame49.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame130.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame129.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame126.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame201.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame245.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame203.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame204.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame64.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame18.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame252.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame174.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame125.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame274.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame207.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame127.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame32.jpg (deflated 1%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame244.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame246.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame30.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame200.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame19.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame251.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame88.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame202.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame140.jpg (deflated 6%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame63.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame72.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame139.jpg (deflated 6%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame31.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame122.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame47.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame33.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame94.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/sad/frame123.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/ (stored 0%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame233.jpg (deflated 13%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame153.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame146.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame231.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame239.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame236.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame227.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame148.jpg (deflated 8%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame237.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame144.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame131.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame9.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame255.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame256.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame242.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame147.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame80.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame261.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame151.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame132.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame238.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame20.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame150.jpg (deflated 5%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame27.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame259.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame46.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame154.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame228.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame149.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame10.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame243.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame29.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame81.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame15.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame232.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame4.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/angry/frame142.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/ (stored 0%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame183.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame100.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame0.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame99.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame14.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame181.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame78.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame189.jpg (deflated 7%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame192.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame1.jpg (deflated 6%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame212.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame70.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame34.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame184.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame65.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame209.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame69.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame66.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame62.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame157.jpg (deflated 6%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame208.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame193.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame52.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame156.jpg (deflated 7%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame41.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame210.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame101.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame211.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame42.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame17.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame266.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame56.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame191.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame182.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/happy/frame84.jpg (deflated 1%)\n",
            "  adding: Emotion_recognition/training_dataset/Unknown/ (stored 0%)\n",
            "  adding: Emotion_recognition/training_dataset/Unknown/frame143.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/Unknown/frame96.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/Unknown/frame138.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/Unknown/frame145.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/Unknown/frame230.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/Unknown/frame229.jpg (deflated 1%)\n",
            "  adding: Emotion_recognition/training_dataset/Unknown/frame141.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/ (stored 0%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame16.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame277.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame6.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame60.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame254.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame160.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame89.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame178.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame161.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame26.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame179.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame162.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame166.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame28.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame271.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame87.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame45.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame164.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame36.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame35.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame58.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame169.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame85.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame3.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame51.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame57.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame93.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame13.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame241.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame23.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame67.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame2.jpg (deflated 1%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame50.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame61.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame167.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame90.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame278.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame171.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame37.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame168.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame83.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame270.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame173.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame170.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame172.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame59.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame12.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame68.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame5.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame44.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame8.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame71.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame180.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame43.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame135.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame91.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame133.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame240.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame234.jpg (deflated 13%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame7.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame163.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame134.jpg (deflated 5%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame53.jpg (deflated 5%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame235.jpg (deflated 4%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame94.jpg (deflated 2%)\n",
            "  adding: Emotion_recognition/training_dataset/surprised/frame165.jpg (deflated 3%)\n",
            "  adding: Emotion_recognition/retrain.py (deflated 74%)\n",
            "  adding: Emotion_recognition/plotly-test.py (deflated 45%)\n",
            "  adding: Emotion_recognition/run_train_and_classify_befehl.txt (deflated 45%)\n",
            "  adding: Emotion_recognition/get_predictions.py (deflated 54%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZSyS8EbR5DZ",
        "colab_type": "code",
        "outputId": "ba211dd7-b046-4c1a-ec5a-ec630720c0eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python classify.py 'test.jpg'\n",
        "#cd 'Emotion_recognition'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Emotion_recognition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWRZxnopuwJJ",
        "colab_type": "code",
        "outputId": "1911712c-5cb0-49be-e0b6-4bf12a4d3caf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "\n",
        "# speicherorte fuer trainierten graph und labels in train.sh festlegen ##\n",
        "\n",
        "def predict(image_data, sess, softmax_tensor):\n",
        "    # holt labels aus file in array\n",
        "    label_lines = [line.rstrip() for line in tf.gfile.GFile(\"tf_files/retrained_labels.txt\")]\n",
        "    predictions = sess.run(softmax_tensor, \\\n",
        "              {'DecodeJpeg/contents:0': image_data})\n",
        "    # gibt prediction values in array zuerueck:\n",
        "\n",
        "    top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]\n",
        "    # sortierung; circle -> 0, plus -> 1, square -> 2, triangle -> 3; array return bsp [3 1 2 0] -> sortiert nach groesster uebereinstimmmung\n",
        "\n",
        "    # output\n",
        "    emotion = label_lines[top_k[0]]\n",
        "    score = predictions[0][top_k[0]]\n",
        "    #print('%s (score = %.5f)' % (emotion, score))\n",
        "\n",
        "    return (emotion, score)\n",
        "\n",
        "def main():\n",
        "    IMAGES_PATH = '/content/drive/My Drive/test_frames/'\n",
        "    output = pd.DataFrame(columns = ['Frame_ID', 'Emotion'])\n",
        "\n",
        "    df = pd.read_csv('../Test_annotated.csv')\n",
        "    images_list = os.listdir(IMAGES_PATH)\n",
        "    unknown_class_images = list(set(images_list) - set(df['Frame_ID']))\n",
        "    print(unknown_class_images)\n",
        "\n",
        "    for image_id, img_name in enumerate(df.Frame_ID.unique()):\n",
        "        image_df = df[df.Frame_ID == img_name]\n",
        "        image = cv2.imread(IMAGES_PATH + img_name)\n",
        "        max_score = 0\n",
        "        for _, row in image_df.iterrows():\n",
        "            face = image[int(row['y_min']):int(row['y_max']), int(row['x_min']):int(row['x_max'])]\n",
        "            success, encoded_face = cv2.imencode('.png', face)\n",
        "            byte_array = encoded_face.tobytes()\n",
        "             # Disable tensorflow compilation warnings\n",
        "            os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
        "            \n",
        "            # !! labels befinden sich jeweils in eigenen lines -> keine aenderung in retrain.py noetig -> falsche darstellung im windows editor !!\n",
        "\n",
        "            # graph einlesen, wurde in train.sh -> call retrain.py trainiert\n",
        "            with tf.gfile.FastGFile(\"tf_files/retrained_graph.pb\", 'rb') as f:\n",
        "\n",
        "                graph_def = tf.GraphDef()\t## The graph-graph_def is a saved copy of a TensorFlow graph; objektinitialisierung\n",
        "                graph_def.ParseFromString(f.read())\t#Parse serialized protocol buffer data into variable\n",
        "                _ = tf.import_graph_def(graph_def, name='')\t# import a serialized TensorFlow GraphDef protocol buffer, extract objects in the GraphDef as tf.Tensor\n",
        "\n",
        "              #https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/inception.py ; ab zeile 276\n",
        "\n",
        "            with tf.Session() as sess:\n",
        "\n",
        "                softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
        "              # return: Tensor(\"final_result:0\", shape=(?, 4), dtype=float32); stringname definiert in retrain.py, zeile 1064\n",
        "\n",
        "                emotion, score = predict(byte_array, sess, softmax_tensor)\n",
        "            if score > max_score:\n",
        "              max_score = score\n",
        "              emotion_class = emotion\n",
        "        index = int(''.join(list(filter(str.isdigit, img_name))))\n",
        "        output.loc[index]=[img_name, emotion_class]\n",
        "        print(img_name, emotion_class)\n",
        "\n",
        "    for img_name in unknown_class_images:\n",
        "         index = int(''.join(list(filter(str.isdigit, img_name))))\n",
        "         output.loc[index]=[img_name, 'Unknown']\n",
        "         print(img_name, 'Unknown')\n",
        "\n",
        "    output = output.sort_index(axis = 0)\n",
        "    output.to_csv('Test.csv', header=True, index=None)\n",
        "#if __name__ == '__main__':\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "['test7.jpg', 'test179.jpg', 'test144.jpg', 'test57.jpg', 'test117.jpg', 'test79.jpg', 'test37.jpg', 'test47.jpg', 'test67.jpg', 'test6.jpg', 'test136.jpg', 'test145.jpg', 'test122.jpg', 'test119.jpg', 'test101.jpg', 'test148.jpg', 'test133.jpg', 'test135.jpg', 'test123.jpg', 'test102.jpg', 'test104.jpg', 'test137.jpg', 'test107.jpg', 'test100.jpg', 'test103.jpg', 'test78.jpg', 'test35.jpg', 'test168.jpg', 'test28.jpg', 'test118.jpg', 'test25.jpg', 'test38.jpg', 'test134.jpg', 'test131.jpg', 'test71.jpg', 'test115.jpg', 'test40.jpg', 'test48.jpg', 'test5.jpg', 'test166.jpg', 'test31.jpg', 'test41.jpg', 'test39.jpg', 'test132.jpg', 'test139.jpg']\n",
            "WARNING:tensorflow:From <ipython-input-15-13efc6dad80f>:49: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n",
            "test0.jpg happy\n",
            "test1.jpg angry\n",
            "test2.jpg surprised\n",
            "test3.jpg sad\n",
            "test4.jpg angry\n",
            "test8.jpg sad\n",
            "test9.jpg sad\n",
            "test10.jpg happy\n",
            "test11.jpg happy\n",
            "test12.jpg happy\n",
            "test13.jpg angry\n",
            "test14.jpg happy\n",
            "test15.jpg happy\n",
            "test16.jpg happy\n",
            "test17.jpg surprised\n",
            "test18.jpg happy\n",
            "test19.jpg surprised\n",
            "test20.jpg surprised\n",
            "test21.jpg angry\n",
            "test22.jpg angry\n",
            "test23.jpg angry\n",
            "test24.jpg angry\n",
            "test26.jpg happy\n",
            "test27.jpg happy\n",
            "test29.jpg surprised\n",
            "test30.jpg sad\n",
            "test32.jpg sad\n",
            "test33.jpg sad\n",
            "test34.jpg happy\n",
            "test36.jpg sad\n",
            "test42.jpg angry\n",
            "test43.jpg sad\n",
            "test44.jpg sad\n",
            "test45.jpg sad\n",
            "test46.jpg happy\n",
            "test49.jpg angry\n",
            "test50.jpg angry\n",
            "test51.jpg angry\n",
            "test52.jpg angry\n",
            "test53.jpg surprised\n",
            "test54.jpg surprised\n",
            "test55.jpg sad\n",
            "test56.jpg sad\n",
            "test58.jpg happy\n",
            "test59.jpg happy\n",
            "test60.jpg happy\n",
            "test61.jpg sad\n",
            "test62.jpg sad\n",
            "test63.jpg sad\n",
            "test64.jpg angry\n",
            "test65.jpg happy\n",
            "test66.jpg angry\n",
            "test68.jpg angry\n",
            "test69.jpg angry\n",
            "test70.jpg angry\n",
            "test72.jpg angry\n",
            "test73.jpg angry\n",
            "test74.jpg sad\n",
            "test75.jpg angry\n",
            "test76.jpg angry\n",
            "test77.jpg surprised\n",
            "test80.jpg sad\n",
            "test81.jpg surprised\n",
            "test82.jpg angry\n",
            "test83.jpg sad\n",
            "test84.jpg angry\n",
            "test85.jpg happy\n",
            "test86.jpg surprised\n",
            "test87.jpg sad\n",
            "test88.jpg surprised\n",
            "test89.jpg sad\n",
            "test90.jpg sad\n",
            "test91.jpg angry\n",
            "test92.jpg angry\n",
            "test93.jpg surprised\n",
            "test94.jpg sad\n",
            "test95.jpg sad\n",
            "test96.jpg happy\n",
            "test97.jpg angry\n",
            "test98.jpg angry\n",
            "test99.jpg sad\n",
            "test105.jpg sad\n",
            "test106.jpg angry\n",
            "test108.jpg surprised\n",
            "test109.jpg angry\n",
            "test110.jpg angry\n",
            "test111.jpg sad\n",
            "test112.jpg sad\n",
            "test113.jpg sad\n",
            "test114.jpg happy\n",
            "test116.jpg sad\n",
            "test120.jpg angry\n",
            "test121.jpg sad\n",
            "test124.jpg surprised\n",
            "test125.jpg sad\n",
            "test126.jpg sad\n",
            "test127.jpg happy\n",
            "test128.jpg angry\n",
            "test129.jpg happy\n",
            "test130.jpg surprised\n",
            "test138.jpg happy\n",
            "test140.jpg surprised\n",
            "test141.jpg surprised\n",
            "test142.jpg happy\n",
            "test143.jpg sad\n",
            "test146.jpg angry\n",
            "test147.jpg happy\n",
            "test149.jpg angry\n",
            "test150.jpg angry\n",
            "test151.jpg angry\n",
            "test152.jpg angry\n",
            "test153.jpg sad\n",
            "test154.jpg angry\n",
            "test155.jpg angry\n",
            "test156.jpg sad\n",
            "test157.jpg sad\n",
            "test158.jpg angry\n",
            "test159.jpg angry\n",
            "test160.jpg angry\n",
            "test161.jpg happy\n",
            "test162.jpg angry\n",
            "test163.jpg angry\n",
            "test164.jpg sad\n",
            "test165.jpg angry\n",
            "test167.jpg sad\n",
            "test169.jpg sad\n",
            "test170.jpg sad\n",
            "test171.jpg happy\n",
            "test172.jpg surprised\n",
            "test173.jpg angry\n",
            "test174.jpg happy\n",
            "test175.jpg sad\n",
            "test176.jpg angry\n",
            "test177.jpg surprised\n",
            "test178.jpg surprised\n",
            "test180.jpg happy\n",
            "test181.jpg happy\n",
            "test182.jpg sad\n",
            "test183.jpg angry\n",
            "test184.jpg sad\n",
            "test185.jpg angry\n",
            "test7.jpg Unknown\n",
            "test179.jpg Unknown\n",
            "test144.jpg Unknown\n",
            "test57.jpg Unknown\n",
            "test117.jpg Unknown\n",
            "test79.jpg Unknown\n",
            "test37.jpg Unknown\n",
            "test47.jpg Unknown\n",
            "test67.jpg Unknown\n",
            "test6.jpg Unknown\n",
            "test136.jpg Unknown\n",
            "test145.jpg Unknown\n",
            "test122.jpg Unknown\n",
            "test119.jpg Unknown\n",
            "test101.jpg Unknown\n",
            "test148.jpg Unknown\n",
            "test133.jpg Unknown\n",
            "test135.jpg Unknown\n",
            "test123.jpg Unknown\n",
            "test102.jpg Unknown\n",
            "test104.jpg Unknown\n",
            "test137.jpg Unknown\n",
            "test107.jpg Unknown\n",
            "test100.jpg Unknown\n",
            "test103.jpg Unknown\n",
            "test78.jpg Unknown\n",
            "test35.jpg Unknown\n",
            "test168.jpg Unknown\n",
            "test28.jpg Unknown\n",
            "test118.jpg Unknown\n",
            "test25.jpg Unknown\n",
            "test38.jpg Unknown\n",
            "test134.jpg Unknown\n",
            "test131.jpg Unknown\n",
            "test71.jpg Unknown\n",
            "test115.jpg Unknown\n",
            "test40.jpg Unknown\n",
            "test48.jpg Unknown\n",
            "test5.jpg Unknown\n",
            "test166.jpg Unknown\n",
            "test31.jpg Unknown\n",
            "test41.jpg Unknown\n",
            "test39.jpg Unknown\n",
            "test132.jpg Unknown\n",
            "test139.jpg Unknown\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd3aRHVG7rc5",
        "colab_type": "code",
        "outputId": "2fc93617-1068-4ccb-ee9c-e6fd370a798e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd Emotion_reconition_colab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Emotion_reconition_colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzd4PWz1Tz7d",
        "colab_type": "code",
        "outputId": "efed218e-0b19-4678-d5bb-b8003f0a888f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "df = pd.DataFrame(columns=['name', 'emotion'])\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [name, emotion]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E92U2LQRT4HB",
        "colab_type": "code",
        "outputId": "f3323954-9f5b-4c09-819f-b1c99ae9e0dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "df.loc[7]=['ritika', 'sad']\n",
        "df.loc[4]=['jatin', 'happy']\n",
        "df.loc[0]=['kavita', 'angry']\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ritika</td>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jatin</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kavita</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     name emotion\n",
              "7  ritika     sad\n",
              "4   jatin   happy\n",
              "0  kavita   angry"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se5OKcJeVcnb",
        "colab_type": "code",
        "outputId": "cf4603f9-f991-4924-fc57-904656403005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "df = df.sort_index(axis = 0)\n",
        "df.to_csv('../test.csv', header=True, index = False)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kavita</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jatin</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ritika</td>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     name emotion\n",
              "0  kavita   angry\n",
              "4   jatin   happy\n",
              "7  ritika     sad"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3IUetsZijsb",
        "colab_type": "code",
        "outputId": "d286f77d-74c8-422e-f3a1-35d38d035725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "str1 = 'test34.jpg'\n",
        "num = int(''.join(list(filter(str.isdigit, str1))))\n",
        "num"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}