{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion-Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riti1302/Cartoon-Emotion-Recognition/blob/master/Emotion_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCxPVbzxMdXT",
        "colab_type": "code",
        "outputId": "7e1b32cb-8f15-4211-d54b-61b12b79812a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPlwQVTPNHaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Emotion_recognition.zip\" -d \"./\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb-EjhOwOEws",
        "colab_type": "code",
        "outputId": "9890fcf5-7d90-4458-9699-c4d984162a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd 'Emotion_recognition'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Emotion_recognition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X232_tThPHiq",
        "colab_type": "code",
        "outputId": "e0ca321c-2ca1-411d-d917-074be89984e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "!pip3 install tensorflow==1.15.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 39kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.28.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 46.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.34.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 44.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=7d7ac417c73d9e8f1f1549c4a7d6a10920faa5aba0e4ce278fd0a452300d5712\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorboard, gast, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorflow 2.2.0rc2\n",
            "    Uninstalling tensorflow-2.2.0rc2:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc2\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deMLGJebOOLD",
        "colab_type": "code",
        "outputId": "4c4259f2-0a70-46c5-d4e8-2bdf0de10120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!sh train.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From retrain.py:1106: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:805: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "W0415 06:55:19.875270 139999072065408 module_wrapper.py:139] From retrain.py:805: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:807: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0415 06:55:19.875519 139999072065408 module_wrapper.py:139] From retrain.py:807: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            ">> Downloading inception-2015-12-05.tgz 100.0%\n",
            "Successfully downloaded inception-2015-12-05.tgz 88931400 bytes.\n",
            "WARNING:tensorflow:From retrain.py:262: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n",
            "W0415 06:55:21.923820 139999072065408 deprecation.py:323] From retrain.py:262: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n",
            "WARNING:tensorflow:From retrain.py:263: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "W0415 06:55:21.924152 139999072065408 module_wrapper.py:139] From retrain.py:263: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "2020-04-15 06:55:22.260277: W tensorflow/core/framework/op_def_util.cc:357] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\n",
            "Looking for images in 'sad'\n",
            "Looking for images in 'angry'\n",
            "Looking for images in 'happy'\n",
            "Looking for images in 'Unknown'\n",
            "WARNING: Folder has less than 20 images, which may cause issues.\n",
            "Looking for images in 'surprised'\n",
            "WARNING:tensorflow:From retrain.py:831: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0415 06:55:22.441224 139999072065408 module_wrapper.py:139] From retrain.py:831: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-04-15 06:55:22.442599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-04-15 06:55:22.494665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-15 06:55:22.495583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-15 06:55:22.520885: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-04-15 06:55:22.760109: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-04-15 06:55:22.870452: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-04-15 06:55:22.896784: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-04-15 06:55:23.158333: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-04-15 06:55:23.295950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-04-15 06:55:23.300416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-15 06:55:23.300585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-15 06:55:23.301651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-15 06:55:23.302476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-04-15 06:55:23.302895: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-04-15 06:55:23.307721: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-04-15 06:55:23.308066: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x283abc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-15 06:55:23.308107: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-04-15 06:55:23.417116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-15 06:55:23.418212: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x283ad80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-15 06:55:23.418243: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-04-15 06:55:23.419790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-15 06:55:23.420685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-15 06:55:23.420755: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-04-15 06:55:23.420778: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-04-15 06:55:23.420796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-04-15 06:55:23.420818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-04-15 06:55:23.420855: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-04-15 06:55:23.420874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-04-15 06:55:23.420894: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-15 06:55:23.421019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-15 06:55:23.422028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-15 06:55:23.422841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-04-15 06:55:23.422887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-04-15 06:55:23.424556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-15 06:55:23.424595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-04-15 06:55:23.424611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-04-15 06:55:23.424765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-15 06:55:23.425757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-15 06:55:23.426500: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-04-15 06:55:23.426605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame253.jpg.txt\n",
            "2020-04-15 06:55:24.761725: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-15 06:55:29.772831: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame49.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame130.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame129.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame126.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame201.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame245.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame203.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame204.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame18.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame252.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame174.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame125.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame274.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame127.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame32.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame244.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame30.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame200.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame19.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame251.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame88.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame202.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame140.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame63.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame72.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame139.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame31.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame122.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame33.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame94.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame123.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame48.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame246.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame124.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame206.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame64.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame207.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/sad/frame47.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame233.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame153.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame231.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame227.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame148.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame237.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame131.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame9.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame256.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame242.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame147.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame80.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame261.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame132.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame238.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame20.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame150.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame27.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame259.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame46.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame154.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame228.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame149.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame10.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame29.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame81.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame15.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame232.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame4.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame142.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame146.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame236.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame243.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame239.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame144.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame255.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/angry/frame151.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame100.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame0.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame99.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame14.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame181.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame78.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame189.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame192.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame212.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame70.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame184.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame65.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame69.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame66.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame62.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame157.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame208.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame193.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame52.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame156.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame41.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame210.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame101.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame42.jpg.txt\n",
            "100 bottleneck files created.\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame266.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame182.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame84.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame209.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame191.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame183.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame1.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame34.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame211.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame17.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/happy/frame56.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/Unknown/frame143.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/Unknown/frame138.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/Unknown/frame230.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/Unknown/frame229.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/Unknown/frame141.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/Unknown/frame96.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/Unknown/frame145.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame16.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame277.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame6.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame60.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame254.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame160.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame89.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame178.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame161.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame26.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame179.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame162.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame28.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame271.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame87.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame45.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame36.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame35.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame169.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame85.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame57.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame93.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame13.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame241.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame23.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame2.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame61.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame167.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame90.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame278.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame171.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame168.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame83.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame270.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame173.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame172.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame59.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame12.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame68.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame44.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame8.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame71.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame180.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame43.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame135.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame91.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame240.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame234.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame7.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame163.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame134.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame94.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame165.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame166.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame164.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame58.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame3.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame50.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame133.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame53.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame51.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame67.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame37.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame170.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame5.jpg.txt\n",
            "Creating bottleneck at tf_files/bottlenecks/surprised/frame235.jpg.txt\n",
            "WARNING:tensorflow:From retrain.py:737: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0415 06:55:38.548075 139999072065408 module_wrapper.py:139] From retrain.py:737: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:741: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0415 06:55:38.549542 139999072065408 module_wrapper.py:139] From retrain.py:741: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:750: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "W0415 06:55:38.550510 139999072065408 module_wrapper.py:139] From retrain.py:750: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:707: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0415 06:55:38.568173 139999072065408 module_wrapper.py:139] From retrain.py:707: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:713: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "W0415 06:55:38.581752 139999072065408 module_wrapper.py:139] From retrain.py:713: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:768: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0415 06:55:38.606792 139999072065408 deprecation.py:323] From retrain.py:768: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:774: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "W0415 06:55:38.628795 139999072065408 module_wrapper.py:139] From retrain.py:774: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:857: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "W0415 06:55:38.674425 139999072065408 module_wrapper.py:139] From retrain.py:857: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:858: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "W0415 06:55:38.675578 139999072065408 module_wrapper.py:139] From retrain.py:858: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From retrain.py:865: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "W0415 06:55:39.418349 139999072065408 module_wrapper.py:139] From retrain.py:865: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "2020-04-15 06:55:40.870040: Step 0: Train accuracy = 26.0%\n",
            "2020-04-15 06:55:40.870132: Step 0: Cross entropy = 1.556131\n",
            "2020-04-15 06:55:41.608796: Step 0: Validation accuracy = 27.0% (N=100)\n",
            "2020-04-15 06:55:42.281949: Step 10: Train accuracy = 71.0%\n",
            "2020-04-15 06:55:42.282070: Step 10: Cross entropy = 1.310120\n",
            "2020-04-15 06:55:42.348960: Step 10: Validation accuracy = 54.0% (N=100)\n",
            "2020-04-15 06:55:43.017447: Step 20: Train accuracy = 75.0%\n",
            "2020-04-15 06:55:43.017530: Step 20: Cross entropy = 1.145645\n",
            "2020-04-15 06:55:43.082421: Step 20: Validation accuracy = 81.0% (N=100)\n",
            "2020-04-15 06:55:43.746742: Step 30: Train accuracy = 76.0%\n",
            "2020-04-15 06:55:43.746830: Step 30: Cross entropy = 0.941239\n",
            "2020-04-15 06:55:43.812578: Step 30: Validation accuracy = 73.0% (N=100)\n",
            "2020-04-15 06:55:44.476924: Step 40: Train accuracy = 81.0%\n",
            "2020-04-15 06:55:44.477038: Step 40: Cross entropy = 0.903699\n",
            "2020-04-15 06:55:44.540001: Step 40: Validation accuracy = 67.0% (N=100)\n",
            "2020-04-15 06:55:45.204325: Step 50: Train accuracy = 84.0%\n",
            "2020-04-15 06:55:45.204399: Step 50: Cross entropy = 0.813072\n",
            "2020-04-15 06:55:45.269208: Step 50: Validation accuracy = 80.0% (N=100)\n",
            "2020-04-15 06:55:45.939530: Step 60: Train accuracy = 78.0%\n",
            "2020-04-15 06:55:45.939620: Step 60: Cross entropy = 0.834105\n",
            "2020-04-15 06:55:46.010192: Step 60: Validation accuracy = 83.0% (N=100)\n",
            "2020-04-15 06:55:46.686219: Step 70: Train accuracy = 78.0%\n",
            "2020-04-15 06:55:46.686294: Step 70: Cross entropy = 0.782897\n",
            "2020-04-15 06:55:46.756065: Step 70: Validation accuracy = 74.0% (N=100)\n",
            "2020-04-15 06:55:47.425714: Step 80: Train accuracy = 81.0%\n",
            "2020-04-15 06:55:47.425797: Step 80: Cross entropy = 0.728158\n",
            "2020-04-15 06:55:47.490163: Step 80: Validation accuracy = 81.0% (N=100)\n",
            "2020-04-15 06:55:48.161192: Step 90: Train accuracy = 85.0%\n",
            "2020-04-15 06:55:48.161270: Step 90: Cross entropy = 0.672086\n",
            "2020-04-15 06:55:48.226579: Step 90: Validation accuracy = 80.0% (N=100)\n",
            "2020-04-15 06:55:48.882564: Step 100: Train accuracy = 92.0%\n",
            "2020-04-15 06:55:48.882637: Step 100: Cross entropy = 0.573852\n",
            "2020-04-15 06:55:48.944393: Step 100: Validation accuracy = 80.0% (N=100)\n",
            "2020-04-15 06:55:49.608057: Step 110: Train accuracy = 86.0%\n",
            "2020-04-15 06:55:49.608141: Step 110: Cross entropy = 0.612825\n",
            "2020-04-15 06:55:49.671624: Step 110: Validation accuracy = 78.0% (N=100)\n",
            "2020-04-15 06:55:50.360393: Step 120: Train accuracy = 92.0%\n",
            "2020-04-15 06:55:50.360479: Step 120: Cross entropy = 0.536408\n",
            "2020-04-15 06:55:50.426349: Step 120: Validation accuracy = 76.0% (N=100)\n",
            "2020-04-15 06:55:51.097886: Step 130: Train accuracy = 89.0%\n",
            "2020-04-15 06:55:51.098002: Step 130: Cross entropy = 0.590495\n",
            "2020-04-15 06:55:51.166387: Step 130: Validation accuracy = 75.0% (N=100)\n",
            "2020-04-15 06:55:51.839326: Step 140: Train accuracy = 89.0%\n",
            "2020-04-15 06:55:51.839399: Step 140: Cross entropy = 0.559205\n",
            "2020-04-15 06:55:51.905135: Step 140: Validation accuracy = 85.0% (N=100)\n",
            "2020-04-15 06:55:52.570760: Step 150: Train accuracy = 93.0%\n",
            "2020-04-15 06:55:52.570848: Step 150: Cross entropy = 0.495591\n",
            "2020-04-15 06:55:52.635090: Step 150: Validation accuracy = 79.0% (N=100)\n",
            "2020-04-15 06:55:53.294089: Step 160: Train accuracy = 95.0%\n",
            "2020-04-15 06:55:53.294207: Step 160: Cross entropy = 0.516430\n",
            "2020-04-15 06:55:53.361955: Step 160: Validation accuracy = 90.0% (N=100)\n",
            "2020-04-15 06:55:54.085590: Step 170: Train accuracy = 93.0%\n",
            "2020-04-15 06:55:54.085673: Step 170: Cross entropy = 0.491999\n",
            "2020-04-15 06:55:54.153711: Step 170: Validation accuracy = 81.0% (N=100)\n",
            "2020-04-15 06:55:54.821450: Step 180: Train accuracy = 96.0%\n",
            "2020-04-15 06:55:54.821556: Step 180: Cross entropy = 0.474432\n",
            "2020-04-15 06:55:54.886832: Step 180: Validation accuracy = 80.0% (N=100)\n",
            "2020-04-15 06:55:55.553371: Step 190: Train accuracy = 93.0%\n",
            "2020-04-15 06:55:55.553445: Step 190: Cross entropy = 0.445112\n",
            "2020-04-15 06:55:55.616385: Step 190: Validation accuracy = 68.0% (N=100)\n",
            "2020-04-15 06:55:56.288000: Step 200: Train accuracy = 97.0%\n",
            "2020-04-15 06:55:56.288081: Step 200: Cross entropy = 0.459678\n",
            "2020-04-15 06:55:56.351017: Step 200: Validation accuracy = 90.0% (N=100)\n",
            "2020-04-15 06:55:57.014770: Step 210: Train accuracy = 96.0%\n",
            "2020-04-15 06:55:57.014865: Step 210: Cross entropy = 0.400006\n",
            "2020-04-15 06:55:57.078931: Step 210: Validation accuracy = 77.0% (N=100)\n",
            "2020-04-15 06:55:57.750489: Step 220: Train accuracy = 95.0%\n",
            "2020-04-15 06:55:57.750570: Step 220: Cross entropy = 0.399987\n",
            "2020-04-15 06:55:57.814493: Step 220: Validation accuracy = 84.0% (N=100)\n",
            "2020-04-15 06:55:58.473215: Step 230: Train accuracy = 98.0%\n",
            "2020-04-15 06:55:58.473285: Step 230: Cross entropy = 0.370849\n",
            "2020-04-15 06:55:58.535828: Step 230: Validation accuracy = 80.0% (N=100)\n",
            "2020-04-15 06:55:59.199640: Step 240: Train accuracy = 97.0%\n",
            "2020-04-15 06:55:59.199725: Step 240: Cross entropy = 0.367684\n",
            "2020-04-15 06:55:59.264315: Step 240: Validation accuracy = 79.0% (N=100)\n",
            "2020-04-15 06:55:59.924769: Step 250: Train accuracy = 98.0%\n",
            "2020-04-15 06:55:59.924871: Step 250: Cross entropy = 0.371842\n",
            "2020-04-15 06:55:59.990715: Step 250: Validation accuracy = 76.0% (N=100)\n",
            "2020-04-15 06:56:00.645480: Step 260: Train accuracy = 97.0%\n",
            "2020-04-15 06:56:00.645616: Step 260: Cross entropy = 0.359272\n",
            "2020-04-15 06:56:00.708062: Step 260: Validation accuracy = 86.0% (N=100)\n",
            "2020-04-15 06:56:01.366347: Step 270: Train accuracy = 100.0%\n",
            "2020-04-15 06:56:01.366448: Step 270: Cross entropy = 0.350360\n",
            "2020-04-15 06:56:01.428968: Step 270: Validation accuracy = 77.0% (N=100)\n",
            "2020-04-15 06:56:02.086167: Step 280: Train accuracy = 94.0%\n",
            "2020-04-15 06:56:02.086258: Step 280: Cross entropy = 0.397118\n",
            "2020-04-15 06:56:02.150378: Step 280: Validation accuracy = 81.0% (N=100)\n",
            "2020-04-15 06:56:02.818089: Step 290: Train accuracy = 98.0%\n",
            "2020-04-15 06:56:02.818181: Step 290: Cross entropy = 0.348624\n",
            "2020-04-15 06:56:02.881950: Step 290: Validation accuracy = 83.0% (N=100)\n",
            "2020-04-15 06:56:03.540643: Step 300: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:03.540716: Step 300: Cross entropy = 0.379627\n",
            "2020-04-15 06:56:03.604222: Step 300: Validation accuracy = 76.0% (N=100)\n",
            "2020-04-15 06:56:04.260972: Step 310: Train accuracy = 97.0%\n",
            "2020-04-15 06:56:04.261072: Step 310: Cross entropy = 0.353126\n",
            "2020-04-15 06:56:04.323858: Step 310: Validation accuracy = 91.0% (N=100)\n",
            "2020-04-15 06:56:04.994876: Step 320: Train accuracy = 98.0%\n",
            "2020-04-15 06:56:04.994999: Step 320: Cross entropy = 0.321202\n",
            "2020-04-15 06:56:05.059729: Step 320: Validation accuracy = 79.0% (N=100)\n",
            "2020-04-15 06:56:05.727714: Step 330: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:05.727798: Step 330: Cross entropy = 0.254424\n",
            "2020-04-15 06:56:05.791292: Step 330: Validation accuracy = 77.0% (N=100)\n",
            "2020-04-15 06:56:06.457593: Step 340: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:06.457673: Step 340: Cross entropy = 0.343786\n",
            "2020-04-15 06:56:06.521238: Step 340: Validation accuracy = 83.0% (N=100)\n",
            "2020-04-15 06:56:07.194781: Step 350: Train accuracy = 96.0%\n",
            "2020-04-15 06:56:07.194856: Step 350: Cross entropy = 0.294712\n",
            "2020-04-15 06:56:07.257400: Step 350: Validation accuracy = 78.0% (N=100)\n",
            "2020-04-15 06:56:07.945447: Step 360: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:07.945534: Step 360: Cross entropy = 0.369786\n",
            "2020-04-15 06:56:08.009547: Step 360: Validation accuracy = 86.0% (N=100)\n",
            "2020-04-15 06:56:08.664563: Step 370: Train accuracy = 98.0%\n",
            "2020-04-15 06:56:08.664638: Step 370: Cross entropy = 0.269893\n",
            "2020-04-15 06:56:08.727862: Step 370: Validation accuracy = 78.0% (N=100)\n",
            "2020-04-15 06:56:09.381595: Step 380: Train accuracy = 98.0%\n",
            "2020-04-15 06:56:09.381670: Step 380: Cross entropy = 0.301910\n",
            "2020-04-15 06:56:09.446410: Step 380: Validation accuracy = 79.0% (N=100)\n",
            "2020-04-15 06:56:10.103786: Step 390: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:10.103878: Step 390: Cross entropy = 0.285069\n",
            "2020-04-15 06:56:10.169066: Step 390: Validation accuracy = 85.0% (N=100)\n",
            "2020-04-15 06:56:10.825376: Step 400: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:10.825486: Step 400: Cross entropy = 0.245422\n",
            "2020-04-15 06:56:10.889537: Step 400: Validation accuracy = 79.0% (N=100)\n",
            "2020-04-15 06:56:11.549722: Step 410: Train accuracy = 98.0%\n",
            "2020-04-15 06:56:11.549792: Step 410: Cross entropy = 0.268487\n",
            "2020-04-15 06:56:11.614284: Step 410: Validation accuracy = 79.0% (N=100)\n",
            "2020-04-15 06:56:12.293645: Step 420: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:12.293759: Step 420: Cross entropy = 0.233880\n",
            "2020-04-15 06:56:12.360075: Step 420: Validation accuracy = 74.0% (N=100)\n",
            "2020-04-15 06:56:13.027921: Step 430: Train accuracy = 100.0%\n",
            "2020-04-15 06:56:13.028022: Step 430: Cross entropy = 0.254580\n",
            "2020-04-15 06:56:13.093468: Step 430: Validation accuracy = 78.0% (N=100)\n",
            "2020-04-15 06:56:13.756765: Step 440: Train accuracy = 100.0%\n",
            "2020-04-15 06:56:13.756849: Step 440: Cross entropy = 0.237364\n",
            "2020-04-15 06:56:13.821658: Step 440: Validation accuracy = 71.0% (N=100)\n",
            "2020-04-15 06:56:14.491207: Step 450: Train accuracy = 100.0%\n",
            "2020-04-15 06:56:14.491290: Step 450: Cross entropy = 0.229077\n",
            "2020-04-15 06:56:14.554491: Step 450: Validation accuracy = 79.0% (N=100)\n",
            "2020-04-15 06:56:15.217391: Step 460: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:15.217482: Step 460: Cross entropy = 0.283302\n",
            "2020-04-15 06:56:15.281079: Step 460: Validation accuracy = 77.0% (N=100)\n",
            "2020-04-15 06:56:15.940674: Step 470: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:15.940769: Step 470: Cross entropy = 0.255519\n",
            "2020-04-15 06:56:16.005969: Step 470: Validation accuracy = 76.0% (N=100)\n",
            "2020-04-15 06:56:16.705565: Step 480: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:16.705662: Step 480: Cross entropy = 0.248983\n",
            "2020-04-15 06:56:16.774716: Step 480: Validation accuracy = 82.0% (N=100)\n",
            "2020-04-15 06:56:17.442260: Step 490: Train accuracy = 99.0%\n",
            "2020-04-15 06:56:17.442354: Step 490: Cross entropy = 0.224372\n",
            "2020-04-15 06:56:17.508803: Step 490: Validation accuracy = 81.0% (N=100)\n",
            "2020-04-15 06:56:18.102961: Step 499: Train accuracy = 100.0%\n",
            "2020-04-15 06:56:18.103051: Step 499: Cross entropy = 0.222370\n",
            "2020-04-15 06:56:18.167532: Step 499: Validation accuracy = 78.0% (N=100)\n",
            "Final test accuracy = 66.7% (N=15)\n",
            "WARNING:tensorflow:From retrain.py:944: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0415 06:56:18.893560 139999072065408 deprecation.py:323] From retrain.py:944: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0415 06:56:18.893815 139999072065408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 2 variables.\n",
            "I0415 06:56:18.948931 139999072065408 graph_util_impl.py:334] Froze 2 variables.\n",
            "INFO:tensorflow:Converted 2 variables to const ops.\n",
            "I0415 06:56:18.963369 139999072065408 graph_util_impl.py:394] Converted 2 variables to const ops.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZSyS8EbR5DZ",
        "colab_type": "code",
        "outputId": "ba211dd7-b046-4c1a-ec5a-ec630720c0eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python classify.py 'test.jpg'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Emotion_recognition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWRZxnopuwJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "\n",
        "# speicherorte fuer trainierten graph und labels in train.sh festlegen ##\n",
        "\n",
        "def predict(image_data, sess, softmax_tensor):\n",
        "    # holt labels aus file in array\n",
        "    label_lines = [line.rstrip() for line in tf.gfile.GFile(\"tf_files/retrained_labels.txt\")]\n",
        "    predictions = sess.run(softmax_tensor, \\\n",
        "              {'DecodeJpeg/contents:0': image_data})\n",
        "    # gibt prediction values in array zuerueck:\n",
        "\n",
        "    top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]\n",
        "    # sortierung; circle -> 0, plus -> 1, square -> 2, triangle -> 3; array return bsp [3 1 2 0] -> sortiert nach groesster uebereinstimmmung\n",
        "\n",
        "    # output\n",
        "    emotion = label_lines[top_k[0]]\n",
        "    score = predictions[0][top_k[0]]\n",
        "    #print('%s (score = %.5f)' % (emotion, score))\n",
        "\n",
        "    return (emotion, score)\n",
        "\n",
        "def main():\n",
        "    IMAGES_PATH = '/content/drive/My Drive/test_frames/'\n",
        "    output = pd.DataFrame(columns = ['Frame_ID', 'Emotion'])\n",
        "\n",
        "    df = pd.read_csv('../Test_annotated.csv')\n",
        "    images_list = os.listdir(IMAGES_PATH)\n",
        "    unknown_class_images = list(set(images_list) - set(df['Frame_ID']))\n",
        "    print(unknown_class_images)\n",
        "\n",
        "    for image_id, img_name in enumerate(df.Frame_ID.unique()):\n",
        "        image_df = df[df.Frame_ID == img_name]\n",
        "        image = cv2.imread(IMAGES_PATH + img_name)\n",
        "        max_score = 0\n",
        "        for _, row in image_df.iterrows():\n",
        "            face = image[int(row['y_min']):int(row['y_max']), int(row['x_min']):int(row['x_max'])]\n",
        "            success, encoded_face = cv2.imencode('.png', face)\n",
        "            byte_array = encoded_face.tobytes()\n",
        "             # Disable tensorflow compilation warnings\n",
        "            os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
        "            \n",
        "            # !! labels befinden sich jeweils in eigenen lines -> keine aenderung in retrain.py noetig -> falsche darstellung im windows editor !!\n",
        "\n",
        "            # graph einlesen, wurde in train.sh -> call retrain.py trainiert\n",
        "            with tf.gfile.FastGFile(\"tf_files/retrained_graph.pb\", 'rb') as f:\n",
        "\n",
        "                graph_def = tf.GraphDef()\t## The graph-graph_def is a saved copy of a TensorFlow graph; objektinitialisierung\n",
        "                graph_def.ParseFromString(f.read())\t#Parse serialized protocol buffer data into variable\n",
        "                _ = tf.import_graph_def(graph_def, name='')\t# import a serialized TensorFlow GraphDef protocol buffer, extract objects in the GraphDef as tf.Tensor\n",
        "\n",
        "              #https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/inception.py ; ab zeile 276\n",
        "\n",
        "            with tf.Session() as sess:\n",
        "\n",
        "                softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
        "              # return: Tensor(\"final_result:0\", shape=(?, 4), dtype=float32); stringname definiert in retrain.py, zeile 1064\n",
        "\n",
        "                emotion, score = predict(byte_array, sess, softmax_tensor)\n",
        "            if score > max_score:\n",
        "              max_score = score\n",
        "              emotion_class = emotion\n",
        "        index = int(''.join(list(filter(str.isdigit, img_name))))\n",
        "        output.loc[index]=[img_name, emotion_class]\n",
        "        print(img_name, emotion_class)\n",
        "\n",
        "    for img_name in unknown_class_images:\n",
        "         index = int(''.join(list(filter(str.isdigit, img_name))))\n",
        "         output.loc[index]=[img_name, 'Unknown']\n",
        "         print(img_name, 'Unknown')\n",
        "\n",
        "    output = output.sort_index(axis = 0)\n",
        "    output.to_csv('Test.csv', header=True, index=None)\n",
        "#if __name__ == '__main__':\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtGZVCeMQY43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd '../'\n",
        "!zip -r Emotion_recognition.zip Emotion_recognition"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}